## 基础
1. make和new的区别
    - make 只能用来分配及初始化类型为 `slice、map、chan` 的数据。new 可以分配任意类型的数据
    - new 分配返回的是`指针`，即类型 *T。make 返回引用，即 T
    - new 分配的空间被清零。make 分配空间后，会进行初始化

2. 数组和切片的区别
    - array
      - 是固定长度的数组，使用前必须确定数组长度。
      - `值类型`。作为函数的参数，实际传递的是一份数组的拷贝
      - array的长度也是Type的一部分
    - slice
      - `引用类型`，是一个动态指向数组切片的指针，作为函数的参数，传递的是指针
      - 是一个不定长，总是指向底层的数组array的数据结构

3. for range 的时候它的地址会发生变化么？
    - 值拷贝，地址不会变

4. for 循环遍历slice有什么问题
    - 循环次数在循环开始前已经确定
    - 循环的时候会创建每个元素的副本
    - 循环的时候短声明只会在开始时执行一次，后面都是重用

5. go defer多个 defer 的顺序，defer 在什么时机会修改返回值？（for defer），defer recover 的问题？(主要是能不能捕获)
    - go defer是一个`栈`的关系，执行的顺序是 `后进先出`
    - 返回值列表声明了返回值名称和类型，defer会修改返回值
    - recover可以终止panic造成的程序崩溃。它只一个只能在defer中发挥作用的函数，在其他作用域中调用不会发挥作用

6. uint 类型溢出
    - unit运算后溢出不会抛出任何异常，会返回意料之外的结果

7. 介绍 rune 类型
    - type byte = uint8
    - type rune = int32
    - rune类型实质其实就是int32，代表一个 UTF-8 字符，他是go语言内在处理字符串及其便捷的字符单位

8. golang 中解析 tag 是怎么实现的？反射原理是什么？(问的很少，但是代码中用的多)
    - tag通过反射去实现
    - 反射通过接口实现，通过隐式转换，普通类型被转换为interface类型，再从inerface类型转换为反射类型，再从反射类型得到想要的类型和值信息

9. 调用函数传入结构体时，应该传值还是指针？ （Golang 都是值传递）
    - 如果是需要修改原结构体的值，需要传指针
    - 传值不会修改原始结构体的值

10. silce 遇到过哪些坑？
    - 每次对slice做append操作后，这个slice可能更换了引用的数组

11. go struct 能不能比较？
    - 有时候可以比较，有时候不可以比较
      - 当其基本类型包含：slice, map, function时，不能直接比较
      - 同一个struct的两个相同实例，如果成员变量包含指针变量或者带有不能比较的成员，也是不可以直接比较
      - 不同的结构体，相同的值内容，可以通过强制转换后比较。当然，如果包含不可比较类型，也是不可比较的
    - 如果必须要比较，可以通过反射方法`reflect.DeepEqual`去比较
    - struct必须时可比较的，才能作为map的key

12. Go 闭包
    - 闭包是由函数及其相关的引用环境组合而成的实体（即：闭包=函数+引用环境）
    - 闭包可能会导致变量逃逸到堆上来延长变量的生命周期，给gc带来压力
    - 内函数对外函数的变量的修改，是对变量的引用。共享在一个堆上的变量。变量被引用后，它所在的函数结束，这变量也不会马上被销毁。相当于变相延长了函数的生命周期
    - 在for循环的时候，如果闭包使用的是外部的变量，那函数输出的结果依赖于子协程执行时的那一刻的变量值
    - 当clousure所在的函数重新调用时，其closure是新的，其context引用的变量也是重新在heap定义过的
    - defer调用会在当前函数执行结束前才被执行，这些调用被称为延迟调用。defer中使用匿名函数依然是一个闭包

## Context相关
`context`用来解决`goroutine`之间的`退出通知`、`元数据传递`的功能
1. context 结构是什么样的？
    - context是一个接口，定义了四个需要实现的方法：
        - `Deadline` - 返回context.Context被取消的时间，也就是完成工作的截止日期
        - `Done` - 返回一个只读Channel，这个Channel会在当前工作时间完成或者上下文被取消后关闭，多次调用Done方法会返回同一个Channel
        - `Err` - 返回context.Context结束的原因，它只会在Done方法对应的Channel关闭时返回非空的值：
            - 如果context.Context被取消，会返回`Canceled`错误
            - 如果context.Context超时，会返回`DeadlineExceeded`错误
        - `Value` -  从context.Context中获取键对应的值，对于同一个上下文来说，多次调用Value并传入相同的Key会返回相同的结果，该方法可以用来传递请求特定的数据
```go
type Context interface {
	Deadline() (deadline time.Time, ok bool)
	Done() <-chan struct{}
	Err() error
	Value(key interface{}) interface{}
}
```
2. context 使用场景和用途？（基本必问）
    - 主要用于在 goroutine 之间传递取消信号、超时时间、截止时间以及一些共享的值等

## Channel相关
1. channel 是否线程安全？锁用在什么地方？
    - channel是协程不是线程，如果理解为允许多个goroutine同时读写，那它是安全的
    - channel的核心是数据流动，关注到并发问题中的数据流动，把流动的数据放到channel中，就能使用channel解决这个并发问题
    - channel和mutex锁的选择
        - channel的能力是让数据流动起来，擅长的数据流动的场景：
            - 传递数据的所有权，即把某个数据发送给其他协程
            - 分发任务，每一个任务都是一个数据
            - 交流异步结果，结果是一个数据
        - mutex的能力时数据不动，某段时间只给一个协程访问数据的权限，擅长数据位置固定的场景
            - 缓存
            - 状态
2. go channel 的底层实现原理 （数据结构）
```go
type hchan struct {
	qcount uint // 队列中所有的数据总数
	dataqsize uint // 环形队列的size
	buf unsafe.Pointer // 指向dataqsize长度的数组
	elemsize uint16 // 元素大小
	closed uint32
	elemtype *_type // 元素类型
	sendx uint // 已发送的元素在环形队列中的位置
	recvx uint // 已接收的元素在环形队列中的位置
	recvq waitq // 接收者的等待队列
	sendq waitq // 发送者的等待队列

	lock mutex
}
```
![go channel 数据结构](http://pic.pwwtest.com/20220223112913.png)

3. nil、关闭的 channel、有数据的 channel，再进行读、写、关闭会怎么样？（各类变种题型）
例如：go channel close 后读的问题
向为 nil 的 channel 发送数据会怎么样？
    - 关闭未初始化的channel(nil)会panic
    - 重复关闭同一个channel会panic
    - 向已关闭的channel发送消息会panic
    - 已关闭的channel，仍然可以从channel中读取剩余的数据，直到数据全部读取完成
    - 在一个值为nil的channel上发送或接收数据会导致永久堵塞
    - 在使用channel的时候，一个适用的原则是：不要从接收端关闭channel，也不要关闭有多个并发发送者的channel


4. 向 channel 发送数据和从 channel 读数据的流程是什么样的？
    - 写入数据的主要流程如下：
        - 如果接收队列recvq不为空，说明缓冲区中没有数据或者没有缓冲区，此时直接从recvq取出G，并把数据写入，最后讲G唤醒，结束发送过程
        - 如果缓冲区有空余位置，将数据写入缓冲区，结束发送过程
        - 如果缓冲区没有空余位置，讲发送数据写入G，讲当前G加入sendq，进入睡眠，等待被读goroutine唤醒
        - ![](http://pic.pwwtest.com/20220223112701.png)
    - 读取数据主要流程如下：
        - 没有缓冲区时，如果等待发送队列sendq不为空，直接从sendq中读取G，把G中数据读出，最后把G唤醒，结束读取过程
        - 有缓冲区时，如果等待发送队列sendq不为空，说明缓冲区已满，从缓冲区中头部读出消息，把G中数据写入缓冲区尾部，把G唤醒，结束读取过程
        - 如果缓冲区有数据，则从缓冲区中读取数据，结束读取过程
        - 将当前goroutine加入recvq，进入睡眠，等待被写goroutine唤醒
        - ![](http://pic.pwwtest.com/20220223113430.png)

## Map相关
map是设计一种数据结构来维护一个集合的数据，并且可以同时对集合进行增删改查的操作。最主要的数据结构有两种：`哈希查找表(Hash table)`、`搜索树(Search tree)`  

哈希查找表用一个哈希函数将key分配到不同的桶（bucket，也就是数组的不同index）。这样，开销主要是在哈希函数的计算以及数组的常数访问时间。很多场景下，哈希查找表的性能很高。

哈希查找表一般会存在“碰撞”问题，就是说不同的key被哈希到了同一个bucket。一般两种应对方法：`链表法`和`开放地址法`。`链表法`将一个bucket实现成一个链表，落在同一个bucket中的key都会插入到这个链表。`开放地址`则是碰撞发生后，通过一定的规律，在数组的后面挑选“空位”，用来放置新的key。

搜索树法一般是采用自平衡搜索树，包括：AVL树，红黑树。

自平衡搜索树法的最差搜索效率是O(logN)，而哈希查找表最差是O(N)。当然，哈希查找表的平均查找效率是O(1)，如果哈希函数设计的很好，最坏情况基本不会出现。遍历自平衡搜索树，返回的key序列，一般会按照从小到大的顺序；而哈希查找表则是乱序的。

1. map 使用注意的点，并发安全？
    - map的元素不可取址，因为map的元素不是一个变量，而是i 个值
    - map并发读写需要加锁

2. map 循环是有序的还是无序的？
    - 无序
    - map底层使用哈希表实现，在运行过程中会扩容，扩容后顺序也会发生变化；不进行扩容是可以保证有序的，但是为了避免这种不稳定特性，遍历时故意加了随机数

3. map 中删除一个 key，它的内存会释放么？
    - map删除元素后map内存不会释放

4. 怎么处理对 map 进行并发访问？有没有其他方案？ 区别是什么？
    - 可以通过sync.Map官方的并发安全的map处理
    - 或者可以通过原生的map+互斥锁或读写锁mutex
    - sync.Map在读和删场景上的性能是最佳的，写入性能较差

5.  nil map 和空 map 有何不同？
    - nil map是未初始化的map，不能插入值，取值不会报错
    - 与空map基本等价

6. map 的数据结构是什么？是怎么实现扩容？
    - map的结构体是hmap
    ```go
    // A header for a Go map.
    type hmap struct {
        count int // 元素个数，调用len(map)时，直接返回此值
        flags uint8
        B uint8 // buckets的对数log_2
        noverflow uint16 // overflow 的 bucket 近似数
        hash0 uint32 // 计算key的哈希的时候会传入哈希函数
        buckets unsafe.Pointer // 指向buckets的数组，大小为2^B。如果元素个数为0，就为nil
        oldbuckets unsafe.Pointer // 扩容的时候，buckets长度会是oldbuckets的两倍
        nevacuate uintptr // 指示扩容进度，小于此地址的buckets迁移完成
        extra *mapextra // optional fields
    }
    ```
    - ![](http://pic.pwwtest.com/20220224161005.png)
    - Go 语言采用一个 bucket 里装载 8 个 key，定位到某个 bucket 后，还需要再定位到具体的 key，这实际上又用了时间换空间。当然，这样做，要有一个度，不然所有的 key 都落在了同一个 bucket 里，直接退化成了链表，各种操作的效率直接降为 O(n)，是不行的。因此，需要有一个指标来衡量前面描述的情况，这就是`装载因子`。Go 源码里这样定义 `装载因子`：
    ```go
    loadFactor := count / (2^B)
    ```
    - count就是map的元素个数，2^B表死bucket数量。在向map插入新key的时候，会进行条件检测，符合下面两个条件就会触发扩容：
        - 装载因子超过阈值，源码里定义的阈值时6.5
        - overflow 的 bucket 数量过多：当 B 小于 15，也就是 bucket 总数 2^B 小于 2^15 时，如果 overflow 的 bucket 数量超过 2^B；当 B >= 15，也就是 bucket 总数 2^B 大于等于 2^15，如果 overflow 的 bucket 数量超过 2^15。

7. map 取一个 key，然后修改这个值，原 map 数据的值会不会变化
    - 只有当map中存指针的时候，修改值之后才会直接修改原map的值

## GMP 相关
1. 什么是 GMP？（必问）调度过程是什么样的？（对流程熟悉，要求更高，问的较少）
    - G（goroutine）
        - 受管理的轻量级线程，goroutine使用`go`关键词创建
        - goroutine的新建、休眠、恢复、停止都受到go运行时的管理
        - goroutine执行异步操作时会进入休眠状态，待操作完成后再恢复，无需占用系统线程
        - goroutine新建或者恢复时会添加到运行中的队列，等待M取出并运行
    - M（machine）
        - 在当前版本的golang中`等同于系统线程`
        - M可以运行两种代码：
            - go代码。即goroutine，M运行go代码需要一个P
            - 原生代码。例如阻塞的syscall，M运行原生代码不需要P
        - M会从队列中取出G，然后运行G，如果G运行完毕或者进入休眠状态，则从运行队列中取出下一个G运行，周而复始
        - 有时候G需要调用一些无法避免阻塞的原生代码，这时M会释放持有的P并进入阻塞状态，其它M会取得这个P并继续运行队列中的G
        - go需要保证有足够的M可以运行G，不让cpu闲着，也需要保证M的数量不能过多
    - P（process）
        - 代表M运行G所需要的资源
        - P也可以理解为控制go代码的并行度的机制，如果P的数量等于2，代表当前最多只能有两个线程（M）执行go代码。执行原生代码的线程数量不受P控制


2. 进程、线程、协程有什么区别？
    - 进程
        - 进程好比是一个程序，是系统资源分配和调度的最小单位，是操作系统构建的基础
    - 线程
        - 线程依赖于进程，也可被称为轻量级进程，是程序执行流的最小单元。
        - 一个标准的线程由线程ID、当前指令指针（PC）、寄存器集合和堆栈组成。
        - 线程与线程之间的关系相当于程序内任务和任务的关系。
        - 线程拥有自己独立的栈和共享的堆，共享堆，不共享栈。
    - 对操作系统而言，线程是最小的执行单元，进程是最小的资源管理单元。无论是进程还是线程，都是操作系统管理的
    - 协程
        - 协程是一种用户态的轻量线程
        - 协程是一种比线程更加轻量级的一种函数。正如一个进程可以拥有多个线程一样，一个线程可以拥有多个协程。
        - 协程不被操作系统控制，而是完全由程序控制，即在用户态执行。好处就是：性能有大幅度提升，因为不会像线程切换那样消耗资源
        - 一个线程中多个协程的运行时串行的

3. 抢占式调度是如何抢占的？
    - 为什么需要抢占式调度
        - 单个G占用M/P时间太长的话，影响其它goroutine执行
        - 一旦某个G中出现死循环，那个G将永远占用该P和M，导致其他的G得不到调度
    - 早期实现流程（1.14之前）
        - 在每个函数或方法的入口，加上一段额外的代码（morestack），让runtime有机会检查是否抢占
        - 对于没有函数调用，纯算法循环的G，依然无法抢占（1.14）之前；也就是说，除非极端的无限循环或死循环，否则只要G调用函数，goroutine就有抢占G的机会
        - golang1.14引入基于信号量的抢占，解决了上述问题
    - golang1.14基于信号量的抢占流程
        - 首先注册绑定SIGURG信号极其handle
        - sysmon间接性的监测运行超时的P，然后发信号给M
        - M收到信号后休眠当前goroutine并重新进行调度

4. M 和 P 的数量问题？
    - P也可以理解为控制go代码的并行度的机制，如果P的数量等于2，代表当前最多只能有两个线程（M）执行go代码。执行原生代码的线程数量不受P控制

5. 协程怎么退出？
    1. 使用for-range退出
        - `for-range`是使用频率很高的结构，常用他来遍历数据，`range`能够感知channel的关闭，当channel被发送数据的协程关闭时，range就会结束，然后退出循环
        - 它在并发中的使用场景是：当协程只从1个channel中读取数据，然后进行处理，处理后协程退出
    2. 使用,ok退出
        - `for-select`也是使用频率很高的结构，select提供了多路复用的能力，所以for-select可以让函数具有持续处理多个channel的能力。但select没有感知channel的关闭，会引出2个问题：
            1. 继续在关闭的channel上读，会读到传输通道数据类型的零值，如果是指针类型，读到nil，继续处理还会产生nil
            2. 继续在关闭的channel上写，会导致panic
    3. 使用退出通道退出
        - 使用`,ok`来退出使用for-select协程，解决的是当读入数据的通道关闭时，没数据读时程序的正常结束，但是不能处理如下两个场景：
            - 接收的协程要退出了，如果他直接退出，不告知发送协程，发送协程会阻塞
            - 启动了一个工作协程处理数据，如何通知他退出
        - 使用一个专门的通道，发送退出信号，可以解决这类问题。
    - 总结：
        - 发送协程主动关闭通道，接收协程不关闭通道。技巧：把接收方的通道入参声明为只读协程，编译时就会报错
        - 协程处理一个通道，并且是读时，协程优先使用`for-range`，因为`range`可以在通道关闭的时候自动退出协程
        - `,ok`可以处理多个通道关闭，需要关闭当前使用`for-select`的协程
        - 显式关闭通道`stopCh`可以处理主动通知协程关闭的场景

6. map 如何顺序读取？
    - 可以将map中的key全部拿出来，放到一个数组里，然后排序后遍历，再取对应的map的值即可

## 锁相关
1. 除了 mutex 以外还有那些方式安全读写共享变量？
    - 可以通过channel进行安全读写共享变量

2. Go 如何实现原子操作？
    - 通过`sync/atomic`提供了对原子操作的支持

3. Mutex 是悲观锁还是乐观锁？悲观锁、乐观锁是什么？
    - mutex是悲观锁，也就是互斥锁，可以通过信号量来控制
    - 乐观锁
        - 即操作时很乐观，认为操作不会产生并发问题（不会有其他线程对数据进行修改），因此不会上锁。但是在更新时会判断其他线程在这之前有没有对数据进行修改，一般使用`版本号机制`或`CAS（compare and swap）算法`实现
        - CAS的缺点
            - `ABA`问题
            - 循环时间长开销大
            - 只能保证一个共享变量的原子操作
    - 悲观锁
        - 总是假设最坏情况，每次取数据时都认为其他线程会修改，所以都会加（悲观）锁，不同线程执行时，只有一个线程执行，其他的线程在入口处等待，直到锁被释放
            - MySQL的读锁、写锁、行锁等
            - Java的`synchronized`关键字

4. Mutex 有几种模式？
    - 分为两种抢锁模式：【`正常模式`】、【`饥饿模式`】
    - 正常模式
        - 刚开始的时候，是处于正常模式，也就是当G1持有着一个锁的时候，G2会自旋的去尝试获取这个锁。
        - 当「`自旋超过4次`」还没有获取到锁的时候，这个G2就会被加入到获取锁的等待队列里。而这个G在队列中的顺序就是根据信号量来决定的
        - 这时候如果G1释放了这个锁，G2就会被从队列中唤醒，然后去竞争这个锁，这时候还有其他正在自旋中的G也在争抢这把锁
        - 这时候因为G2是被唤醒来去争抢锁的，相对于在CPU中本身已经在自旋状态的G4和G5，更不容易获得这个锁，这时候如果获取失败，`G2就会被重新加入到等待队列的头部`，继续下一轮等待
        - 这样如果长时间得不到执行，就会进入`饥饿模式`
    - 饥饿模式
        - 当处于等待队列中的goroutine超过1ms没有获取到锁的话，他的状态会变成饥饿模式，这个时候如果G1把锁给释放出来的时候，`G2可以直接获取到这个锁`，而不用通过去争抢的方式，同时，`后续的G4和G5也不会进入自旋的状态`，而是直接进入到等待队列的后面

5. goroutine 的自旋占用资源如何解决
    - 通过「`自旋+队列排队`」的方式，来增加更大的一个吞吐量，但是这种方式，很容易出现一个尾端延迟执行的情况。
    - 而在饥饿模式下，则会把goroutine加入到队列中去，严格的按照顺序执行，这样就不会带来尾端延迟执行的问题。但是相应的，程序的吞吐量也就没有正常模式下来的高

6. 读写锁底层是怎么实现的？
    - go通过int32变量记录当前正在读的goroutine数
    - 大概过程如下：
        1. 如果没有write请求进来，则每个reader开始后只是将readerCount加1，完成后将readerCount减1，整个过程不阻塞，这样就做到“并发读之间不互斥”
        2. 当有write请求进来时，首先通过互斥锁阻塞新进来的writer，做到“并发写操作之间互斥”
        3. 然后将readerCount改成一个很小的值，从而阻塞住新来的reader
        4. 记录writer进来之前未完成的的reader数量，等待他们都完成后再唤醒writer；这样就做到了“并发读操作和写操作互斥”
        5. write结束后将readerCount重置为原来的值，保证新的reader不会被阻塞，然后唤醒之前等待的reader，再将互斥锁匙放，使后续writer不会被阻塞

## 同步原语相关
[知道哪些 sync 同步原语？各有什么作用？](https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-sync-primitives/)
 
sync.pool 问的相对多些

- 常见的同步原语有：`sync.Mutex`、`sync.RWMutex`、`sync.WaitGroup`、`sync.Once`、`sync.Cond`以及扩展原语`golang/sync/errgroup.Group`、`golang/sync/semaphore.Weighted`和`golang/sync/singleflight.Group`
- 各有什么作用
1. Mutex: 互斥锁
   - 如果互斥锁处于初始状态，会通过置为`mutexLocked`状态加锁
   - 如果互斥锁处于`muextLocked`状态并且在普通模式下工作，会进入自旋，执行30次`PAUSE`指令消耗CPU时间等待锁的释放
   - 如果当前goroutine等待锁的时间超过1ms，互斥锁就会切换为饥饿模式
   - 互斥锁在正常情况下会通过`runtime.sync_runtime_SemacquireMutex`将尝试获取锁的goroutine切换至休眠状态，等待锁的持有者唤醒
   - 如果当前goroutine是互斥锁上的最后一个等待的协程或者等待的时间小于1ms，那么它会将互斥锁切换为正常模式
   - 互斥锁的解锁流程
       - 当互斥锁已经被解锁时，调用`sync.Mutex.Unlock`会直接抛出异常
       - 当互斥锁处于饥饿模式时，将锁的所有权转交给队列中的下一个等待者，等待者会负责设置`mutexLocked`标志位
       - 当互斥锁处于普通模式时，如果没有goroutine等待锁的释放或者已经有被唤醒的goroutine获得了锁，会直接返回；在其他情况下会通过`sync.runtime_Semrelease`唤醒对应的goroutine

2. RWMutex: 读写互斥锁，是细粒度的互斥锁
   - 调用`sync.RWMutex.Lock`尝试获取写锁时：
       - 每次`sync.RWUnlock`都会将`readCount`减一，当他归零时该routinue会获得写锁
       - 将`readCount`减少`rwmutexMaxReaders`个数以阻塞后续的读操作
   - 调用`sync.RWMutex.Unlock`释放写锁时，会先通知所有的读操作，然后才会释放持有的互斥锁
   - 读写互斥锁在互斥锁之上提供了额外的更细粒度的控制，能够在读操作远多余写操作时提升性能

3. sync.WaitGroup
   - `sync.WaitGroup`可以等待一组goroutinue的返回，一个比较常见的场景是批量发出RPC或者HTTP请求
    ```golang
    requests := []*Request{...}
    wg := &sync.WaitGroup{}
    wg.Add(len(requests))

    for _, request := range requests {
        go func(r *Request) {
            defer wg.Done()
            // res, err := service.call(r)
        }(request)
    }
    wg.Wait()
    ```

4. sync.Once
   - `sync.Once`可以保证在Go程序运行期间某段代码只会执行一次
   - `sync.Once.Do`方法中传入的函数只会执行被执行一次，哪怕函数中发生了panic
   - 两次调用`sync.Once.DO`方法传入不同的函数只会执行第一次传入的函数
   - 结构体
    ```golang
    type Once struct {
        done uint32
        m    Mutex
    }
    ```

5. sync.Cond
   - 条件变量`sync.Cond`，可以让一组goroutine都在满足特定条件时被唤醒。每一个`sync.Cond`结构体在初始化的时都需要传入一个互斥锁。

## 并发相关
1. 怎么控制并发数？
   - channel缓冲区
   - sync.waitGroup
   - 协程池
  
2. 多个 goroutine 对同一个 map 写会 panic，异常是否可以用 defer 捕获？
   - 会产生fatal error直接导致整个进程退出，不能被recover捕获

3. 如何优雅的实现一个 goroutine 池（百度、手写代码）

4. select 可以用于什么？
   - 能够让goroutine同时等待多个channel可读或者可写，在多个文件或者channel状态改变之前，select会一直阻塞当前线程或者goroutine
   - 多路复用
  
5. 主协程如何等其余协程完再操作？
   - sync.waitGroup

## GC 相关
1. go gc 是怎么实现的？（必问）
   - 三色标记法
2. go 是 gc 算法是怎么实现的？ （得物，出现频率低）
3. GC 中 stw 时机，各个阶段是如何解决的？ （百度）
4. GC 的触发时机？
   - 系统触发
     - gcTriggerHeap：当所分配的堆大小达到阈值（由控制器计算的触发堆的大小）时，将会触发
     - gcTriggerTime：当距离上一个GC周期的时间超过一定时间时，将会触发。时间周期以runtime.forcegcperiod变量为准，默认2分钟
     - gcTriggerCycle：如果没有开启 GC，则启动 GC
   - 手动触发
     - runtime.GC

## 内存相关
1. 谈谈内存泄露，什么情况下内存会泄露？怎么定位排查内存泄漏问题？
2. 知道 golang 的内存逃逸吗？什么情况下会发生内存逃逸？
   - 局部变量通过堆分配和回收，就叫内存逃逸
   - 函数返回局部指针变量
   - interface类型逃逸
   - 闭包产生逃逸
   - 变量大小不确定以及栈空间不足引发逃逸
   - 总结：
     - 逃逸分析在编译阶段确定哪些变量可以分配在栈上，哪些变量分配在堆上
     - 逃逸分析减轻了gc的压力，提高程序运行速度
     - 栈上内存使用完毕不需要gc处理，堆上内存使用完毕会交给gc处理
     - 函数传参时对于需要修改原对象值，或占用内存比较大的结构体，选择传指针。对于只读的占用内存较小的结构体，直接传值能够获得更好的性能
     - 根据代码具体分析，尽量减少逃逸代码，减轻gc压力，提高性能
3. 请简述 Go 是如何分配内存的？
Channel 分配在栈上还是堆上？哪些对象分配在堆上，哪些对象分配在栈上？
    - 堆内存管理
      - 分配内存块
      - 回收内存块
      - 组织内存块
    - go通过TCMalloc管理内存
      - 为每个线程预分配一块缓存，线程申请小内存时，可以从缓存分配内存，有两个好处：
        - 为线程分配预缓存需要进行一次系统调用，后续线程申请小内存时，从
    - channel分配在堆上
    - 对象分类
      - 小对象（大小<=32kb）
      - 大对象（大小>32kb）
4. 介绍一下大对象小对象，为什么小对象多了会造成 gc 压力？
5. 堆和栈的区别？
   - 管理方式不同：栈由操作系统自动分配释放，无需手动控制；堆的申请和释放由人控制，容易产生内存泄漏
   - 空间大小不同：每个进程拥有的栈的大小远远小于堆大小
   - 生长方向不同：堆的生长方向向上，内存地址由低到高；栈的生长方向向下，内存地址由高到低
   - 分配方式不同：堆事动态分配的，没有静态分配的堆。栈有2种分配方式：静态分配、动态分配。
   - 分配效率不同：栈由操作系统分配，硬件级别、指令支持，效率较高。堆一般是库函数申请和管理，较为复杂，效率低
   - 存放内容不同：栈存放函数返回地址、相关参数、局部变量和寄存器内容等。
6. 当 go 服务部署到线上了，发现有内存泄露，该怎么处理？

## 微服务框架
1. go-micro 微服务架构怎么实现水平部署的，代码怎么实现？
2. 怎么做服务发现的
   - 微服务的服务发现主要包含三个角色：提供者、消费者、注册表
     - 服务提供者：服务启动时将服务信息注册到注册表，服务退出时将服务注册表的服务信息删除
     - 服务消费者：从服务注册表获取服务提供者的最新网络位置等服务信息，维护与服务提供者之间的通信
     - 服务注册表：联系服务提供者和消费者的桥梁，维护服务提供者的最新网络位置等服务信息
   - 服务发现如何解决微服务实例地址动态变化的问题，主要有两种：客户端发现模式、服务端发现模式
     - 客户端发现模式
       - 客户端负责确定服务提供者的可用实例地址列表和负载均衡策略。客户端访问服务注册表，定时同步目标服务的实例地址列表。比如ETCD
       - 优点
         - 客户端可以灵活智能地制定负载均衡策略
         - 去中心化通讯
         - 客户端以sdk引入，整合度最高，性能最佳，方便排查
       - 缺点
         - 客户端与注册表耦合，需要为客户端各种语言实现服务发现逻辑
         - sdk引入，需要更新，要求客户端所有程序重新编译，更新困难
     - 服务端发现模式
       - 客户端通过路由器（或者负载均衡器）访问目标服务。路由器负责查询服务注册表，获取目标服务实例的地址列表转发请求。例如docker和k8s
       - 优点
         - 部署平台的服务发现功能仅支持发现使用该平台部署的服务。例如基于k8s的服务发现仅适用于k8s上部署运行的服务
         - 服务的架构增加了一次转发，延迟时间会增加。整个系统增加了一个故障点，运维难度增加。负载转发请求的路由器或者负载均衡器可能会变成性能瓶颈
   - Service Mesh服务网格是服务于微服务应用程序的可配置基础设施层

## 其他
1. go 实现单例的方式？
   - sync.Once
2. 项目中使用 go 遇到的坑？
3. client 如何实现长连接？
   - http.Transport设置长连接，同时设置超时时间，循环遍历

## 编程题
1. 3 个函数分别打印 cat、dog、fish，要求每个函数都要起一个 goroutine，按照 cat、dog、fish 顺序打印在屏幕上 100 次。
2. 如何优雅的实现一个 goroutine 池？

